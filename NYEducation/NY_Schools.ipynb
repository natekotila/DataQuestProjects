{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import pandas as pd\n",
    "data_files = [\n",
    "    \"ap_2010.csv\",\n",
    "    \"class_size.csv\",\n",
    "    \"demographics.csv\",\n",
    "    \"graduation.csv\",\n",
    "    \"hs_directory.csv\",\n",
    "    \"sat_results.csv\"\n",
    "]\n",
    "data = {}\n",
    "path = \"schools/\"\n",
    "\n",
    "for file in data_files:\n",
    "    name = file.split(\".\")[0]\n",
    "    data[name] = pd.read_csv(path + file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(data['sat_results'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DBN', 'SCHOOL NAME', 'Num of SAT Test Takers',\n",
       "       'SAT Critical Reading Avg. Score', 'SAT Math Avg. Score',\n",
       "       'SAT Writing Avg. Score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['sat_results'].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ap_2010', 'class_size', 'demographics', 'graduation', 'hs_directory', 'sat_results'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key in data.keys():\n",
    "#     print(data[key].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N_p</th>\n",
       "      <th>N_s</th>\n",
       "      <th>N_t</th>\n",
       "      <th>aca_p_11</th>\n",
       "      <th>aca_s_11</th>\n",
       "      <th>aca_t_11</th>\n",
       "      <th>aca_tot_11</th>\n",
       "      <th>bn</th>\n",
       "      <th>com_p_11</th>\n",
       "      <th>com_s_11</th>\n",
       "      <th>...</th>\n",
       "      <th>t_q8c_1</th>\n",
       "      <th>t_q8c_2</th>\n",
       "      <th>t_q8c_3</th>\n",
       "      <th>t_q8c_4</th>\n",
       "      <th>t_q9</th>\n",
       "      <th>t_q9_1</th>\n",
       "      <th>t_q9_2</th>\n",
       "      <th>t_q9_3</th>\n",
       "      <th>t_q9_4</th>\n",
       "      <th>t_q9_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.9</td>\n",
       "      <td>7.9</td>\n",
       "      <td>M015</td>\n",
       "      <td>7.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>29.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>161.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.0</td>\n",
       "      <td>7.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.1</td>\n",
       "      <td>8.4</td>\n",
       "      <td>M019</td>\n",
       "      <td>7.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>74.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>367.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.0</td>\n",
       "      <td>8.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>M020</td>\n",
       "      <td>8.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>33.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7.8</td>\n",
       "      <td>7.9</td>\n",
       "      <td>M034</td>\n",
       "      <td>8.2</td>\n",
       "      <td>5.9</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "      <td>7.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>M063</td>\n",
       "      <td>7.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>59.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2773 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     N_p    N_s   N_t  aca_p_11  aca_s_11  aca_t_11  aca_tot_11    bn  \\\n",
       "0   90.0    NaN  22.0       7.8       NaN       7.9         7.9  M015   \n",
       "1  161.0    NaN  34.0       7.8       NaN       9.1         8.4  M019   \n",
       "2  367.0    NaN  42.0       8.6       NaN       7.5         8.0  M020   \n",
       "3  151.0  145.0  29.0       8.5       7.4       7.8         7.9  M034   \n",
       "4   90.0    NaN  23.0       7.9       NaN       8.1         8.0  M063   \n",
       "\n",
       "   com_p_11  com_s_11   ...    t_q8c_1  t_q8c_2  t_q8c_3 t_q8c_4  t_q9  \\\n",
       "0       7.6       NaN   ...       29.0     67.0      5.0     0.0   NaN   \n",
       "1       7.6       NaN   ...       74.0     21.0      6.0     0.0   NaN   \n",
       "2       8.3       NaN   ...       33.0     35.0     20.0    13.0   NaN   \n",
       "3       8.2       5.9   ...       21.0     45.0     28.0     7.0   NaN   \n",
       "4       7.9       NaN   ...       59.0     36.0      5.0     0.0   NaN   \n",
       "\n",
       "   t_q9_1  t_q9_2  t_q9_3  t_q9_4  t_q9_5  \n",
       "0     5.0    14.0    52.0    24.0     5.0  \n",
       "1     3.0     6.0     3.0    78.0     9.0  \n",
       "2     3.0     5.0    16.0    70.0     5.0  \n",
       "3     0.0    18.0    32.0    39.0    11.0  \n",
       "4    10.0     5.0    10.0    60.0    15.0  \n",
       "\n",
       "[5 rows x 2773 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_survey = pd.read_csv(path + \"survey_all.txt\", sep = '\\t', encoding = 'windows-1252')\n",
    "\n",
    "d75_survey = pd.read_csv(path + 'survey_d75.txt', sep = '\\t', encoding = 'windows-1252')\n",
    "\n",
    "survey = pd.concat([all_survey, d75_survey], axis=0)\n",
    "\n",
    "survey.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey['DBN'] = survey['dbn']\n",
    "\n",
    "cols = [\"DBN\", \"rr_s\", \"rr_t\", \"rr_p\", \"N_s\", \"N_t\", \"N_p\", \"saf_p_11\", \"com_p_11\", \n",
    "        \"eng_p_11\", \"aca_p_11\", \"saf_t_11\", \"com_t_11\", \"eng_t_11\", \"aca_t_11\", \"saf_s_11\", \n",
    "        \"com_s_11\", \"eng_s_11\", \"aca_s_11\", \"saf_tot_11\", \"com_tot_11\", \"eng_tot_11\", \"aca_tot_11\"]\n",
    "\n",
    "survey = survey[cols]\n",
    "\n",
    "data['survey'] = survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csd_to_string(csd):\n",
    "    return str(csd).zfill(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['hs_directory']['DBN'] = data['hs_directory']['dbn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CSD', 'BOROUGH', 'SCHOOL CODE', 'SCHOOL NAME', 'GRADE ',\n",
       "       'PROGRAM TYPE', 'CORE SUBJECT (MS CORE and 9-12 ONLY)',\n",
       "       'CORE COURSE (MS CORE and 9-12 ONLY)', 'SERVICE CATEGORY(K-9* ONLY)',\n",
       "       'NUMBER OF STUDENTS / SEATS FILLED', 'NUMBER OF SECTIONS',\n",
       "       'AVERAGE CLASS SIZE', 'SIZE OF SMALLEST CLASS', 'SIZE OF LARGEST CLASS',\n",
       "       'DATA SOURCE', 'SCHOOLWIDE PUPIL-TEACHER RATIO'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['class_size'].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['class_size']['CSD'] = data['class_size']['CSD'].apply(csd_to_string)\n",
    "\n",
    "data['class_size']['DBN'] = data['class_size']['CSD'] + data['class_size']['SCHOOL CODE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['sat_results']['SAT Math Avg. Score'] = pd.to_numeric(data['sat_results']['SAT Math Avg. Score'],errors = 'coerce')\n",
    "data['sat_results']['SAT Critical Reading Avg. Score'] = pd.to_numeric(data['sat_results']['SAT Critical Reading Avg. Score'], errors = 'coerce')\n",
    "data['sat_results']['SAT Writing Avg. Score'] = pd.to_numeric(data['sat_results']['SAT Writing Avg. Score'], errors = 'coerce')\n",
    "\n",
    "data['sat_results']['sat_score'] = data['sat_results']['SAT Math Avg. Score'] + data['sat_results']['SAT Critical Reading Avg. Score'] + data['sat_results']['SAT Writing Avg. Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DBN', 'SCHOOL NAME', 'Num of SAT Test Takers',\n",
       "       'SAT Critical Reading Avg. Score', 'SAT Math Avg. Score',\n",
       "       'SAT Writing Avg. Score', 'sat_score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['sat_results'].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    883 Classon Avenue\\nBrooklyn, NY 11225\\n(40.67...\n",
       "1    1110 Boston Road\\nBronx, NY 10456\\n(40.8276026...\n",
       "2    1501 Jerome Avenue\\nBronx, NY 10452\\n(40.84241...\n",
       "3    411 Pearl Street\\nNew York, NY 10038\\n(40.7106...\n",
       "4    160 20 Goethals Avenue\\nJamaica, NY 11432\\n(40...\n",
       "Name: Location 1, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['hs_directory']['Location 1'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def lats_extraction(string):\n",
    "    coords = re.findall(\"\\(.+\\)\", string)[0]\n",
    "    coords = re.sub(r'[\\(\\),]', ' ', coords).split()\n",
    "    return coords[0]\n",
    "\n",
    "def long_extraction(string):\n",
    "    coords = re.findall(\"\\(.+\\)\", string)[0]\n",
    "    coords = re.sub(r'[\\(\\),]', ' ', coords).split()\n",
    "    return coords[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = data['hs_directory']['Location 1'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40.67029890700047, -73.96164787599963) ['40.67029890700047', '-73.96164787599963']\n"
     ]
    }
   ],
   "source": [
    "test2 = re.findall('\\(.+\\)', test)[0]\n",
    "test3 = re.sub(r'[\\(\\),]', ' ', test2).split()\n",
    "print(test2, test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['hs_directory']['lat'] = data['hs_directory']['Location 1'].apply(lats_extraction)\n",
    "data['hs_directory']['lon'] = data['hs_directory']['Location 1'].apply(long_extraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['hs_directory']['lat'] = pd.to_numeric(data['hs_directory']['lat'], errors = 'coerce')\n",
    "data['hs_directory']['lon'] = pd.to_numeric(data['hs_directory']['lon'], errors = 'coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
